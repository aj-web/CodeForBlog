---
title: 特征工程基础
date: 2021年9月1日17:21:32
tags: 机器学习
------

>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;机器学习适用的数据为具有特征值(属性，label)和目标值(结果,point)的数据集。通过从历史数据集中学习经验，建立模型，从而达到预测新特征值对应的目标值的效果。因此在数据方面，越见多识广的数据集(样本集越大越全)，越能进行更可信的预测(越准确的预测)。
<!--more-->

# 1. KNN算法
1.**定义：**  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;如果一个样本在特征空间中的K个最相似(距离最近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。人以类聚，物以群分。  

2.**距离计算公式：**  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;欧式距离(平方根距离)、曼哈顿距离(绝对值距离)，明科夫斯基距离(以上两种距离均是明科夫斯基距离的特例)

3.**适用案例：**  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;iris，根据鸢尾花的一些特征判断一个鸢尾花所属的种类，适用于小数据场景，K-W数据量级别的样本

4.**算法优缺点：**  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;优点：简单、易于理解，易于实现，无需训练
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;缺点：1、懒惰算法，对预测样本分类时才进行计算，计算量大，内存开销大。 2、必须指定K值，K值选择会极大程度影响分类的准确度。 关于K值选取：K值过小，容易受到异常数据的影响。而K值过大，容易受样本不均衡的影响。

5.**特征工程处理：**  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;需尽量保证各个维度的数据公平性。无量纲化-标准化处理。尽量保证各个维度的数据公平性。

6.**skLearn API:**
```
	sklearn.neighbors.KNeighborsClassifier(n_neighbor=5,algrithm='auto')
		n_neighbors: int 可选，默认5 ， K值
		algorithm : {'auto','ball_tree','kd_tree','brute'} .可选。用于计算最近的算法。有ball_tree、kd_tree。不同的实现方式会影响效率，但不影响结果。一般用auto，会自己根据fit方法的值来选择合适的算法。
```

# 2. 朴素贝叶斯算法

# 3. 决策树

# 4. 随机森林

# 5. 线性回归

# 6. 逻辑回归与二分类

# 7. 无监督学习-K-means算法

