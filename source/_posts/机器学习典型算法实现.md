---
title: 特征工程基础
date: 2021年9月1日17:21:32
tags: 机器学习
------

>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;机器学习适用的数据为具有特征值(属性，label)和目标值(结果,point)的数据集。通过从历史数据集中学习经验，建立模型，从而达到预测新特征值对应的目标值的效果。因此在数据方面，越见多识广的数据集(样本集越大越全)，越能进行更可信的预测(越准确的预测)。
<!--more-->

# 1. KNN算法
1.**定义：**  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;如果一个样本在特征空间中的K个最相似(距离最近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。人以类聚，物以群分。  

2.**距离计算公式：**  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;欧式距离(平方根距离)、曼哈顿距离(绝对值距离)，明科夫斯基距离(以上两种距离均是明科夫斯基距离的特例)

3.**适用案例：**  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;iris，根据鸢尾花的一些特征判断一个鸢尾花所属的种类，适用于小数据场景，K-W数据量级别的样本

4.**算法优缺点：**  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;优点：简单、易于理解，易于实现，无需训练
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;缺点：1、懒惰算法，对预测样本分类时才进行计算，计算量大，内存开销大。 2、必须指定K值，K值选择会极大程度影响分类的准确度。 关于K值选取：K值过小，容易受到异常数据的影响。而K值过大，容易受样本不均衡的影响。

5.**特征工程处理：**  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;需尽量保证各个维度的数据公平性。无量纲化-标准化处理。尽量保证各个维度的数据公平性。

6.**skLearn API:**
```
	sklearn.neighbors.KNeighborsClassifier(n_neighbor=5,algrithm='auto')
		n_neighbors: int 可选，默认5 ， K值
		algorithm : {'auto','ball_tree','kd_tree','brute'} .可选。用于计算最近的算法。有ball_tree、kd_tree。不同的实现方式会影响效率，但不影响结果。一般用auto，会自己根据fit方法的值来选择合适的算法。
```

# 2. 朴素贝叶斯算法

&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;1.朴素：假定了特征与特征之间相互独立，没有影响。  
贝叶斯：贝叶斯概率计算公式。

**原理：**

&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;2.朴素的概率计算：30%的男人是好人，80%的老人是好人， 那男老人有24%的概率是好人。

> 概率基础知识：独立的定义 P(A,B) = P(A)*P(B)
>
> 全概率公式： P(A)=P(A|B1)\*P(B1)+P(A|B2)\*P(B2)+P(A|B3)\*P(B3)+P(A|B4)\*P(B4)+。。。。

**3.应用场景：**  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;文本分类、评论区分好差评

**4.优缺点：**  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;优点：发源于古典数学理论，有稳定的分类效率。对缺失数据不敏感，算法也比较简单，常用语文本分类。  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;分类速度快，准确度相对较高。  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;缺点：由于使用了样本属性独立的假设，当特征属性之间有关联时，其效果就不太好。  
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;基于概率论的简单统计，样本数量越大越好。

**5.Sklearn API:**

```
	sklearn.naive_bayes.MuitinomialNB(alpha = 1.0)
	alpha:拉普拉斯平滑系数，一般用1 。用来防止计算出的概率为0.使用方式是在分子和分母上一起添加平滑系数。
```

# 3. 决策树

# 4. 随机森林

# 5. 线性回归

# 6. 逻辑回归与二分类

# 7. 无监督学习-K-means算法

